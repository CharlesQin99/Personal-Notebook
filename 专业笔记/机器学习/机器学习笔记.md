

# 机器学习笔记整理

## 定义

![](pic\1.JPG)

![](pic\2.JPG)

本质为根据经验E来提高指标P的问题，典型的**最优化**问题

## 基础知识

## 分类

### **监督学习** Supervised Learning

输入E是由人工采集并输入进计算机

基于标签性质可以分为**分类问题**和**回归问题**

其中**分类**针对**离散值**（如人脸识别），**回归**针对**连续值**（如预测房价，股票，年龄等）

#### 传统监督学习

每一个训练数据都有对应的标签

##### 支持向量机 SVM

##### 人工神经网络 NN

##### 深度神经网络 DNN

#### 非监督学习

所有训练数据都没有标签，主要是分类

##### 聚类 Clustering

##### EM算法 Expectation Maximization

##### 主成分分析 PCA



#### 半监督学习

训练数据中一部分有标签，一部分没有

![](pic\4.JPG)

### 强化学习 Reinforecement Learning

计算机通过与环境交互，改变自己的行为模式去**最大化收益函数**

**这个划分并不绝对**，**经常会有混合使用光的情况**

![](pic\3.JPG)

## 机器学习算法过程

### 特征提取

提取差的特征，算法不可能获得好的性能，**提取特征的方式千变万化**，机器学习假设以及获得特征的前提下研究合理的算法，使得学习系统获得比较好的性能

### 特征选择

特征空间的维度可以高于2维

### 应用算法对特征空间做划分

不同的算法在不同的特征空间做的划分肯定有所不同



## 支持向量机SVM

### 训练样本集线性可分

线性可分，存在一条直线可以准确分类样本空间

![](pic\5.JPG)



### 最优化问题

支持向量机找的就是间隔最大的那一条直线，且这条线在这两个平行线正中间

![](pic\6.JPG)

#### 最优分类满足条件

1. 直线分开两类
2. 直线最大化间隔margin
3. 直线处于间隔的正中间，到所有支持向量距离相等

> 高维空间中，直线变为超平面

#### 数学定义

![](pic\7.JPG)



### 线性不可分情况

### 核函数

### 算法流程

![](pic\8.JPG)

求解优化问题后求出alpha 和 常数b

测试过程：

![](pic\9.JPG)

### 国际象棋中的兵王问题（实际问题）

在训练样本求出每个维度的均值和方差，在训练和测试样本同时归一化

![](pic\10.JPG)

### ROC曲线

![](pic\11.JPG)

![](pic\12.JPG)

#### ROC性能指标

![](pic\13.JPG)

越贴近左上角性能越好（同样FP下，TP的样本数更多）

#### AUC

ROC曲线下的面积，**AUC越大，系统性能越好**

![](pic\14.JPG)

#### EER

**交ROC曲线为一点，这一点为EER，这点的FP=FN**

**EER越低，系统性能越好**

![15](pic\15.JPG)

### 多分类问题

#### 1类对K-1类

需要构造K个支持向量机模型

![](pic\16.JPG)

#### 1类对另一类

![](pic\17.JPG)

K(K-1)/2个支持向量机

#### 树状分类器

![](pic\18.JPG)



## 决策树

### 决策树概念

ten space 实例空间X

假设H

实例和实例标签构成的一组信息叫做**训练样例**

![](pic\19.JPG)

**非叶子节点：属性，特征**

**每一个分支：上面特征的取值**

**最终叶子结点：标签label，决策**

![](pic\20.JPG)

